{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-43-19deb244bcb2>, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-43-19deb244bcb2>\"\u001b[0;36m, line \u001b[0;32m20\u001b[0m\n\u001b[0;31m    for w in selhttps://github.com/doggy8088/A-Whirlwind-Tour-of-Python-zh-twf.parameters():\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class LSTMCell(nn.Module):\n",
    "    \"\"\"\n",
    "    An implementation of Hochreiter & Schmidhuber:\n",
    "    'Long-Short Term Memory' cell.\n",
    "    http://www.bioinf.jku.at/publications/older/2604.pdf\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, bias=True):\n",
    "        super(LSTMCell, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bias = bias\n",
    "        self.x2h = nn.Linear(input_size, 4 * hidden_size, bias=bias)\n",
    "        self.h2h = nn.Linear(hidden_size, 4 * hidden_size, bias=bias)\n",
    "        self.reset_parameters()\n",
    "    '''\n",
    "    STEP 3: CREATE MODEL CLASS\n",
    "    '''\n",
    "    def reset_parameters(self):\n",
    "        std = 1.0 / math.sqrt(self.hidden_size)\n",
    "        for w in selhttps://github.com/doggy8088/A-Whirlwind-Tour-of-Python-zh-twf.parameters():\n",
    "            w.data.uniform_(-std, std)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        hx, cx = hidden\n",
    "        x = x.view(-1, x.size(1))\n",
    "        gates = self.x2h(x) + self.h2h(hx)\n",
    "        gates = gates.squeeze()\n",
    "        ingate, forgetgate, cellgate, outgate = gates.chunk(4, 1)\n",
    "        ingate = F.sigmoid(ingate)\n",
    "        forgetgate =https://github.com/doggy8088/A-Whirlwind-Tour-of-Python-zh-tw F.sigmoid(forgetgate)\n",
    "        cellgate = F.tanh(cellgate)\n",
    "        outgate = F.sigmoid(outgate)\n",
    "        cy = torch.mul(cx, forgetgate) +  torch.mul(ingate, cellgate)\n",
    "        hy = torch.mul(outgate, F.tanh(cy))\n",
    "\n",
    "        return (hy, cy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, bias=True):\n",
    "        super(LSTMMohttps://github.com/doggy8088/A-Whirlwind-Tour-of-Python-zh-twdel, self).__init__()\n",
    "        # Hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "        # Number of hidden layers\n",
    "        self.layer_dim = layer_dim\n",
    "        self.lstm = LSTMCell(input_dim, hidden_dim, layer_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        #######################\n",
    "        #  USE GPU FOR MODEL  #\n",
    "        #######################\n",
    "        #print(x.shape,\"x.shape\")100, 28, 28\n",
    "        if torch.cuda.is_available():\n",
    "            h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).cuda())\n",
    "        else:\n",
    "            h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n",
    "\n",
    "        # Initialize cell state\n",
    "        if torch.cuda.is_available():\n",
    "            c0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).cuda())\n",
    "        else:\n",
    "            c0 = Variable(torch.zeros(self.layer_dim, x.size(0), hidden_dim))\n",
    "\n",
    "        outs = []\n",
    "        cn = c0[0,:,:]\n",
    "        hn = h0[0,:,:]\n",
    "\n",
    "        for seq in range(x.size(1)):\n",
    "            hn, cn = self.lstm(x[:,seq,:], (hn,cn))\n",
    "            outs.append(hn)\n",
    "\n",
    "        out = outs[-1].squeeze()\n",
    "        out = self.fc(out)\n",
    "        # out.size() --> 100, 10\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTMCcell explaination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![lstm](./ipynb_image/lstm_arc.jpg)\n",
    "ref: 李弘毅 http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2016/Lecture/RNN%20(v2).pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![lstm_another](./ipynb_image/lstm_another_arc.png)\n",
    "ref: https://www.itread01.com/content/1547138353.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 28\n",
    "hidden_dim = 128\n",
    "layer_dim = 1  # ONLY CHANGE IS HERE FROM ONE LAYER TO TWO LAYER\n",
    "output_dim = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start to looking LSTMCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, bias=True):\n",
    "        super(LSTMCell, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bias = bias\n",
    "        self.x2h = nn.Linear(input_size, 4 * hidden_size, bias=bias)     # 28*512\n",
    "        self.h2h = nn.Linear(hidden_size, 4 * hidden_size, bias=bias)    # 128*512\n",
    "        self.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def reset_parameters(self):\n",
    "        std = 1.0 / math.sqrt(self.hidden_size)\n",
    "        for w in self.parameters():\n",
    "            w.data.uniform_(-std, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def forward(self, x, hidden):\n",
    "        hx, cx = hidden\n",
    "        x = x.view(-1, x.size(1))\n",
    "        gates = self.x2h(x) + self.h2h(hx)                           # x2h = z, h2h = zi\n",
    "        gates = gates.squeeze()\n",
    "        ingate, forgetgate, cellgate, outgate = gates.chunk(4, 1)\n",
    "        ingate = F.sigmoid(ingate)\n",
    "        forgetgate = gates = self.x2h(x) + self.h2h(hx) F.sigmoid(forgetgate)\n",
    "        cellgate = F.tanh(cellgate)\n",
    "        outgate = F.sigmoid(outgate)\n",
    "        cy = torch.mul(cx, forgetgate) +  torch.mul(ingate, cellgate) # cy = sigmoid(zf) + \n",
    "        hy = torch.mul(outgate, F.tanh(cy))                           # \n",
    "\n",
    "        return (hy, cy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## relationship between LSTMCell and LSTMModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class LSTMModel(nn.Module):\n",
    "    model = LSTMModel(input_dim, hidden_dim, layer_dim, output_dim)        \n",
    "    self.layer_dim = layer_dim\n",
    "    self.lstm = LSTMCell(input_dim, hidden_dim, layer_dim)\n",
    "\n",
    "class LSTMCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, bias=True):\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## relationship between $\\color{blue}{\\text{input_size}}$ and  $\\color{blue}{\\text{input_dim}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_size = 28\n",
      "hidden_size = 128\n",
      "bias = True\n"
     ]
    }
   ],
   "source": [
    "input_size = input_dim\n",
    "hidden_size = hidden_dim\n",
    "bias = True\n",
    "print('input_size = ' + str(input_size))\n",
    "print('hidden_size = ' + str(hidden_size))\n",
    "print('bias = ' + str(bias))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## in LSTMCell __init__, what is x2h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x2h\t\t\tLinear(in_features=28, out_features=512, bias=True)\n",
      "x2h.weight.shape\ttorch.Size([512, 28])\n",
      "x2h.bias.shape  \ttorch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "x2h = nn.Linear(input_size, 4 * hidden_size, bias=bias)\n",
    "print('x2h\\t\\t\\t' + str(x2h))\n",
    "print('x2h.weight.shape\\t' + str(x2h.weight.shape))\n",
    "print('x2h.bias.shape  \\t' + str(x2h.bias.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## in LSTMCell init, what is h2h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h2h\t\t\tLinear(in_features=128, out_features=512, bias=True)\n",
      "h2h.weight.shape\ttorch.Size([512, 128])\n",
      "h2h.bias.shape  \ttorch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "h2h = nn.Linear(hidden_size, 4 * hidden_size, bias=bias)\n",
    "print('h2h\\t\\t\\t' + str(h2h))\n",
    "print('h2h.weight.shape\\t' + str(h2h.weight.shape))\n",
    "print('h2h.bias.shape  \\t' + str(h2h.bias.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## in LSTMCell forward (1)\n",
    "```python\n",
    "class LSTMCell(nn.Module):\n",
    "    def forward(self, x, hidden):\n",
    "        hx, cx = hidden\n",
    "        x = x.view(-1, x.size(1))\n",
    "        gates = self.x2h(x) + self.h2h(hx)   \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![lstm_x2h](./ipynb_image/lstm_z.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2h "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![lstm](./ipynb_image/lstm_code.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12391729, 0.50678421, 0.46675831, 0.51107347, 0.4245179 ,\n",
       "       0.31237322, 0.52732505, 0.42256535, 0.02678756, 0.6292324 ,\n",
       "       0.78433458, 0.46798546, 0.26293351, 0.41522625, 0.318218  ,\n",
       "       0.28708365, 0.21262692, 0.85536599, 0.63128721, 0.54387477,\n",
       "       0.98303062, 0.80305686, 0.91437346, 0.83764352, 0.43622364,\n",
       "       0.94119711, 0.8048368 , 0.75700112])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.uniform(size=28)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10615313, 0.36155902, 0.44862399, 0.40851203, 0.30983418,\n",
       "       0.5988416 , 0.1034623 , 0.77819937, 0.56643113, 0.04108196,\n",
       "       0.25113469, 0.46300616, 0.63161179, 0.89954969, 0.6572328 ,\n",
       "       0.74300082, 0.36104994, 0.51351677, 0.17867032, 0.70383985,\n",
       "       0.40304291, 0.94785047, 0.49272398, 0.34189683, 0.00942435,\n",
       "       0.96366127, 0.03216598, 0.12580701, 0.85616907, 0.70567649,\n",
       "       0.16650692, 0.10786439, 0.4692811 , 0.98838087, 0.73006358,\n",
       "       0.53382854, 0.75972848, 0.54159603, 0.94619127, 0.42758419,\n",
       "       0.30266943, 0.72731099, 0.67403598, 0.36315002, 0.26021785,\n",
       "       0.87997547, 0.85395045, 0.08603945, 0.8808212 , 0.20220159,\n",
       "       0.77308362, 0.01202031, 0.14407329, 0.34649372, 0.78662467,\n",
       "       0.96914692, 0.48194861, 0.14121417, 0.56645685, 0.91811252,\n",
       "       0.32673359, 0.16988181, 0.26571623, 0.69151312, 0.14059881,\n",
       "       0.14619194, 0.50707507, 0.45898698, 0.96010259, 0.39586481,\n",
       "       0.5155281 , 0.31753012, 0.92634141, 0.10996943, 0.62292247,\n",
       "       0.36679184, 0.16810905, 0.81093002, 0.67169249, 0.10848924,\n",
       "       0.99004196, 0.2431782 , 0.62190101, 0.61505492, 0.3949732 ,\n",
       "       0.58279874, 0.55981476, 0.9090851 , 0.97493244, 0.01999957,\n",
       "       0.55717415, 0.73030849, 0.04835519, 0.08950057, 0.77625737,\n",
       "       0.01028047, 0.72775121, 0.37837603, 0.02084764, 0.37653063,\n",
       "       0.99705365, 0.62902801, 0.37537724, 0.57563983, 0.79504376,\n",
       "       0.12618283, 0.80946787, 0.5477418 , 0.58312534, 0.04532511,\n",
       "       0.22521808, 0.81524604, 0.83478912, 0.41487417, 0.11881763,\n",
       "       0.42454749, 0.82508168, 0.44926663, 0.10490079, 0.8612296 ,\n",
       "       0.33537829, 0.30478401, 0.03666934, 0.35276178, 0.79461188,\n",
       "       0.55473959, 0.07312753, 0.93570918])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn = np.random.uniform(size=128)\n",
    "hn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-207440d18eda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx2h\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1402\u001b[0m         \u001b[0;34m-\u001b[0m \u001b[0mOutput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0m_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1403\u001b[0m     \"\"\"\n\u001b[0;32m-> 1404\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1405\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'dim'"
     ]
    }
   ],
   "source": [
    "x2h(x).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-069c73c45416>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inputs' is not defined"
     ]
    }
   ],
   "source": [
    "x = inputs[0]\n",
    "print(type(x))\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "xn = x.view(-1,x.size(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.squeeze().size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h0.size = torch.Size([1, 1, 128])\n",
      "c0.size = torch.Size([1, 1, 128])\n"
     ]
    }
   ],
   "source": [
    "layer_dim = 1\n",
    "hidden_dim = 128\n",
    "#h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).cuda())\n",
    "h0 = Variable(torch.zeros(layer_dim, x.size(0), hidden_dim).cuda())\n",
    "c0 = Variable(torch.zeros(layer_dim, x.size(0), hidden_dim).cuda())\n",
    "print('h0.size = ' + str(h0.size()))\n",
    "print('c0.size = ' + str(c0.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx = [3, 2.2, 8.8, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-27291aeac13c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "xxx.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-a558c16e0f1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.41959043, 0.66354645, 0.32679139, 0.89560696, 0.88122791,\n",
       "       0.44116725, 0.2319549 , 0.20337702, 0.32658795, 0.96374005,\n",
       "       0.52722275, 0.61603115, 0.28896504, 0.70517421, 0.04906607,\n",
       "       0.13845368, 0.91730347, 0.48181953, 0.6893669 , 0.61514601,\n",
       "       0.2181168 , 0.65531249, 0.66858463, 0.6224446 , 0.12197584,\n",
       "       0.0171417 , 0.73596117, 0.59561187])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0].size(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# geting information about c0,h0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Parameter\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False    \n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor    \n",
    "\n",
    "torch.manual_seed(125)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "STEP 1: LOADING DATASET\n",
    "'''\n",
    "train_dataset = dsets.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    " \n",
    "test_dataset = dsets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    " \n",
    "batch_size = 100\n",
    "n_iters = 6000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    " \n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i 0\n",
      "image size torch.Size([100, 1, 28, 28])\n",
      "label size torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "for i, (image,label) in enumerate(train_loader):\n",
    "    print('i '+ str(i))\n",
    "    print('image size ' + str(image.shape))\n",
    "    print('label size ' + str(label.shape))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images size torch.Size([100, 1, 28, 28])\n",
      "images view torch.Size([100, 28, 28])\n",
      "vairable of images = torch.Size([100, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "for i, (images,label) in enumerate(train_loader):\n",
    "    print('images size ' + str(images.shape))\n",
    "    print('images view ' + str(images.view(-1,28,28).cuda().shape))\n",
    "    images = Variable(images.view(-1,28,28).cuda())\n",
    "    break\n",
    "print('vairable of images = ' + str(images.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_dim = 1\n",
    "x = images\n",
    "hidden_dim = 128\n",
    "h0 = Variable(torch.zeros(layer_dim, x.size(0), hidden_dim).cuda())\n",
    "c0 = Variable(torch.zeros(layer_dim, x.size(0), hidden_dim).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h0 shape = torch.Size([1, 100, 128])\n",
      "c0 shape = torch.Size([1, 100, 128])\n"
     ]
    }
   ],
   "source": [
    "print('h0 shape = ' + str(h0.shape))\n",
    "print('c0 shape = ' + str(c0.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cn.shape = torch.Size([100, 128])\n",
      "hn shape = torch.Size([100, 128])\n"
     ]
    }
   ],
   "source": [
    "outs = []\n",
    "cn = c0[0,:,:]\n",
    "hn = h0[0,:,:]\n",
    "print('cn.shape = ' + str(cn.shape))\n",
    "print('hn shape = ' + str(hn.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seq in range(x.size(1)):\n",
    "    hn, cn = self.lstm(x[:,seq,:], (hn,cn))\n",
    "    #outs.append(hn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuple lenght = 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'),\n",
       " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'))"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('tuple lenght = ' + str(len((hn,cn))))\n",
    "(hn,cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[0,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8452e1e358>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10)) \n",
    "\n",
    "def plot_mnist(index):\n",
    "    ax = plt.subplot(1,10,index+1) \n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.imshow(images[index].cpu(), cmap='gray') \n",
    "    \n",
    "for i,data in enumerate(images,0): \n",
    "    if i == 1: break \n",
    "    plot_mnist(0+i*4)\n",
    "    plot_mnist(1+i*4)\n",
    "    plot_mnist(2+i*4)\n",
    "    plot_mnist(3+i*4)\n",
    "    plot_mnist(4+i*4)\n",
    "    plot_mnist(5+i*4)\n",
    "    plot_mnist(6+i*4)\n",
    "    plot_mnist(7+i*4)\n",
    "    plot_mnist(8+i*4)\n",
    "    plot_mnist(9+i*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p1 type = <class 'torch.Tensor'>\n",
      "p1 shape = torch.Size([100, 28])\n"
     ]
    }
   ],
   "source": [
    "x = images\n",
    "for seq in range(x.size(1)):\n",
    "    #hn, cn = self.lstm(x[:,seq,:], (hn,cn))\n",
    "    p1 = x[:,seq,:]\n",
    "    p2 = (hn,cn)\n",
    "    break\n",
    "print('p1 type = ' + str(type(p1)))\n",
    "print('p1 shape = ' + str(p1.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f84483820b8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image[0][0].cpu(), cmap='gray')\n",
    "print(label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = input_size\n",
    "hidden_size = hidden_size\n",
    "bias = bias\n",
    "x2h = nn.Linear(input_size, 4 * hidden_size, bias=bias)     # 28*512\n",
    "h2h = nn.Linear(hidden_size, 4 * hidden_size, bias=bias)    # 128*512\n",
    "\n",
    "hx, cx = hidden\n",
    "x = x.view(-1, x.size(1))\n",
    "gates = self.x2h(x) + se        for seq in range(x.size(1)):\n",
    "            hn, cn = self.lstm(x[:,seq,:], (hn,cn))\n",
    "            outs.append(hn)lf.h2h(hx)                           # x2h = z, h2h = zi\n",
    "gates = gates.squeeze()\n",
    "ingate, forgetgate, cellgate, outgate = gates.chunk(4, 1)\n",
    "ingate = F.sigmoid(ingate)\n",
    "forgetgate = F.sigmoid(forgetgate)\n",
    "cellgate = F.tanh(cellgate)\n",
    "outgate = F.sigmoid(outhn (100,128)\n",
    "gate)\n",
    "cy = torch.mul(cx, forgetgate) +  torch.mul(ingate, cellgate) # cy = sigmoid(zf) + \n",
    "hy = torch.mul(outgate, F.tanh(cy))                           # \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28\n",
    "hidden_size = 128\n",
    "bias = True\n",
    "x2h = nn.Linear(input_size, 4 * hidden_size, bias=bias)     # 28*512\n",
    "h2h = nn.Linear(hidden_size, 4 * hidden_size, bias=bias)    # 128*512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of backend CPU but got backend CUDA for argument #4 'mat1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-259-b19f9a20b0ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx2h\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1407\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of backend CPU but got backend CUDA for argument #4 'mat1'"
     ]
    }
   ],
   "source": [
    "x2h(x[:,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2h(hn[0].cpu()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "gate = x2h(x[0,0,:].cpu()) + h2h(hn[0].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "gate = gate.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingat, forget, collect, output = gate.chunk(4,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 28, 28])"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 28])"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = images[:,0,:]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = (hn,cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "hx, cx = hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = x2h(x.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 512])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = h2h(hn.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 512])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 512])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 28])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = 0\n",
    "x = images[:,seq,:]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 28])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.view(-1,x.size(1))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 128])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden = (hn,cn)\n",
    "hx,cx = hidden\n",
    "hx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 512])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gates = x2h(x.cpu()) + h2h(hx.cpu())\n",
    "gates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 512])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gates = gates.squeeze()\n",
    "gates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c, d = gates.chunk(4,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a shape = torch.Size([100, 128])\n",
      "b shape = torch.Size([100, 128])\n",
      "c shape = torch.Size([100, 128])\n",
      "d shape = torch.Size([100, 128])\n"
     ]
    }
   ],
   "source": [
    "print('a shape = ' + str(a.shape))\n",
    "print('b shape = ' + str(b.shape))\n",
    "print('c shape = ' + str(c.shape))\n",
    "print('d shape = ' + str(d.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as trimport torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Parameter\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "    \n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor    \n",
    "\n",
    "torch.manual_seed(125)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(125)ansforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Parameter\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "    \n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor    \n",
    "\n",
    "torch.manual_seed(125)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
