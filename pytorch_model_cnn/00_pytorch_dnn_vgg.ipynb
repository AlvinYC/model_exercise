{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://pytorch.org/\n",
    "from os import path\n",
    "#from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "#platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "#accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
    "#!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "#from scikit-learn import multilabel_confusion_matrix\n",
    "from sklearn.metrics import multilabel_confusion_matrix, confusion_matrix, classification_report\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models_cnn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu\n"
     ]
    }
   ],
   "source": [
    "#torch.cuda.device_count()\n",
    "device = \"gpu\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace)\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace)\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace)\n",
      "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU(inplace)\n",
      "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU(inplace)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace)\n",
      "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (36): ReLU(inplace)\n",
      "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (39): ReLU(inplace)\n",
      "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU(inplace)\n",
      "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (44): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      "  (softmax): LogSoftmax()\n",
      ")\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alvin/notebook/pytorch_model_excercise/models_cnn.py:135: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = self.softmax(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.092\n",
      "[1,  4000] loss: 1.911\n",
      "[1,  6000] loss: 1.766\n",
      "[2,  2000] loss: 1.666\n",
      "[2,  4000] loss: 1.573\n",
      "[2,  6000] loss: 1.491\n",
      "[3,  2000] loss: 1.398\n",
      "[3,  4000] loss: 1.354\n",
      "[3,  6000] loss: 1.298\n",
      "[4,  2000] loss: 1.193\n",
      "[4,  4000] loss: 1.170\n",
      "[4,  6000] loss: 1.154\n",
      "[5,  2000] loss: 1.034\n",
      "[5,  4000] loss: 1.033\n",
      "[5,  6000] loss: 1.028\n",
      "[6,  2000] loss: 0.933\n",
      "[6,  4000] loss: 0.921\n",
      "[6,  6000] loss: 0.931\n",
      "[7,  2000] loss: 0.818\n",
      "[7,  4000] loss: 0.846\n",
      "[7,  6000] loss: 0.844\n",
      "[8,  2000] loss: 0.740\n",
      "[8,  4000] loss: 0.746\n",
      "[8,  6000] loss: 0.761\n",
      "[9,  2000] loss: 0.684\n",
      "[9,  4000] loss: 0.678\n",
      "[9,  6000] loss: 0.673\n",
      "[10,  2000] loss: 0.573\n",
      "[10,  4000] loss: 0.604\n",
      "[10,  6000] loss: 0.617\n",
      "Finished Training\n",
      "--- 1456.6239936351776 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#net = Net1()\n",
    "net = Net2()\n",
    "#net = Net3()\n",
    "#net = NetCEI201()\n",
    "net = VGG('VGG16')\n",
    "print(net)\n",
    "net.cuda()\n",
    "\n",
    "data_batch_size = 4\n",
    "start_time = time.time()\n",
    "if __name__ == '__main__':\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    trainset  = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "    ## reduce training size -√ç begin\n",
    "    num_train = len(trainset)\n",
    "    indices   = list(range(num_train))\n",
    "    split     = int(np.floor(0.5 * num_train))\n",
    "    np.random.seed(10)\n",
    "    np.random.shuffle(indices)\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    ## reduce training size - end\n",
    "    #trainloader = torch.utils.data.DataLoader(trainset,batch_size=data_batch_size, shuffle=True, num_workers=2)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset,batch_size=data_batch_size, sampler=train_sampler, num_workers=2)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=data_batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    classes = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "    #optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "    train = True\n",
    "    #train = False\n",
    "    if train:\n",
    "        for epoch in range(10):\n",
    "            running_loss = 0.0\n",
    "\n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "                inputs, labels = data\n",
    "                if device == \"gpu\":\n",
    "                    inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())  \n",
    "                else: \n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "                            \n",
    "                optimizer.zero_grad()\n",
    "                output = net(inputs)\n",
    "                loss = criterion(output, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                #running_loss += loss.data[0]\n",
    "                running_loss += loss.data.item()\n",
    "\n",
    "                if i % 2000 == 1999:\n",
    "                    print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 2000))\n",
    "                    running_loss = 0.0\n",
    "\n",
    "        print('Finished Training')\n",
    "\n",
    "        torch.save(net.state_dict(), './00_cifar10-Net-model')\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct = 7271\n",
      "total = 10000\n",
      "Total test accuracy : 72.71 %\n",
      "Accuracy of plane : 79.00 % on 794, 1000\n",
      "Accuracy of   car : 81.00 % on 812, 1000\n",
      "Accuracy of  bird : 51.00 % on 517, 1000\n",
      "Accuracy of   cat : 54.00 % on 542, 1000\n",
      "Accuracy of  deer : 74.00 % on 749, 1000\n",
      "Accuracy of   dog : 67.00 % on 675, 1000\n",
      "Accuracy of  frog : 77.00 % on 777, 1000\n",
      "Accuracy of horse : 81.00 % on 819, 1000\n",
      "Accuracy of  ship : 77.00 % on 772, 1000\n",
      "Accuracy of truck : 81.00 % on 814, 1000\n"
     ]
    }
   ],
   "source": [
    "net.load_state_dict(torch.load('./00_cifar10-Net-model'))\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "for i, data in enumerate(testloader, 0):\n",
    "    inputs, labels = data\n",
    "    inputs, targets = data\n",
    "    \n",
    "    images = Variable(inputs.cuda()) if device == \"gpu\" else Variable(inputs)\n",
    "    labels = Variable(labels.cuda()) if device == \"gpu\" else Variable(labels)\n",
    "\n",
    "    output = net(images)\n",
    "\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    c = predicted.eq(labels.data).squeeze()\n",
    "    for j in range(4):\n",
    "        label = int(targets[j])\n",
    "        class_correct[label] += int(c[j])\n",
    "        class_total[label] += 1\n",
    "        total += 1\n",
    "        correct += int(c[j])\n",
    "    \n",
    "print('correct = ' + str(correct))\n",
    "print('total = ' + str(total))\n",
    "print('Total test accuracy : %3.2f %%' %(100 * int(correct) / total))\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %3.2f %% on %d, %d' \n",
    "          %(classes[i], 100 * int(class_correct[i]) // int(class_total[i]), class_correct[i],class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct = 7277\n",
      "total = 10000\n",
      "Total test accuracy : 72.77 %\n",
      "Accuracy of plane : 78.00 % on 786, 1000\n",
      "Accuracy of   car : 82.00 % on 820, 1000\n",
      "Accuracy of  bird : 52.00 % on 521, 1000\n",
      "Accuracy of   cat : 54.00 % on 540, 1000\n",
      "Accuracy of  deer : 74.00 % on 744, 1000\n",
      "Accuracy of   dog : 67.00 % on 675, 1000\n",
      "Accuracy of  frog : 77.00 % on 775, 1000\n",
      "Accuracy of horse : 82.00 % on 821, 1000\n",
      "Accuracy of  ship : 78.00 % on 781, 1000\n",
      "Accuracy of truck : 81.00 % on 814, 1000\n",
      "----------------------------\n",
      "confusion matrix\n",
      "[[786   2  73  35  25   3   4  15  35  22]\n",
      " [ 27 820   2  20   1   3  11   6  27  83]\n",
      " [ 60   2 521 126 100 105  54  26   2   4]\n",
      " [ 15   5  46 540  68 221  47  47   5   6]\n",
      " [ 18   0  38  58 744  33  31  78   0   0]\n",
      " [  6   0  24 168  46 675  14  65   2   0]\n",
      " [  4   1  28 129  35  16 775   3   7   2]\n",
      " [ 11   1  11  38  51  64   1 821   0   2]\n",
      " [125   9  13  27   3   7   9   9 781  17]\n",
      " [ 48  49   3  26   2   4   7  35  12 814]]\n"
     ]
    }
   ],
   "source": [
    "net.load_state_dict(torch.load('./00_cifar10-Net-model'))\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "cf_label = []\n",
    "cf_pred = []\n",
    "\n",
    "\n",
    "for i, data in enumerate(testloader, 0):\n",
    "    inputs, labels = data\n",
    "    inputs, targets = data\n",
    "\n",
    "    images = Variable(inputs.cuda())\n",
    "    labels = Variable(labels.cuda())\n",
    "    #images = Variable(inputs)\n",
    "    #labels = Variable(labels)\n",
    "\n",
    "    output = net(images)\n",
    "\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    c = predicted.eq(labels.data).squeeze()\n",
    "    for j in range(4):\n",
    "        label = int(targets[j])\n",
    "        class_correct[label] += int(c[j])\n",
    "        class_total[label] += 1\n",
    "        total += 1\n",
    "        correct += int(c[j])\n",
    "    \n",
    "    cf_label += labels.tolist()                           # <---- here\n",
    "    cf_pred += predicted.tolist()                         # <---- here\n",
    "print('correct = ' + str(correct))\n",
    "print('total = ' + str(total))\n",
    "print('Total test accuracy : %3.2f %%' %(100 * int(correct) / total))\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %3.2f %% on %d, %d' \n",
    "          %(classes[i], 100 * int(class_correct[i]) // int(class_total[i]), class_correct[i],class_total[i]))\n",
    "    \n",
    "cf = confusion_matrix(cf_label, cf_pred)  # <---- here\n",
    "print('----------------------------\\nconfusion matrix')   # <---- here\n",
    "print(cf)                                                 # <---- here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[786,   2,  73,  35,  25,   3,   4,  15,  35,  22],\n",
       "       [ 27, 820,   2,  20,   1,   3,  11,   6,  27,  83],\n",
       "       [ 60,   2, 521, 126, 100, 105,  54,  26,   2,   4],\n",
       "       [ 15,   5,  46, 540,  68, 221,  47,  47,   5,   6],\n",
       "       [ 18,   0,  38,  58, 744,  33,  31,  78,   0,   0],\n",
       "       [  6,   0,  24, 168,  46, 675,  14,  65,   2,   0],\n",
       "       [  4,   1,  28, 129,  35,  16, 775,   3,   7,   2],\n",
       "       [ 11,   1,  11,  38,  51,  64,   1, 821,   0,   2],\n",
       "       [125,   9,  13,  27,   3,   7,   9,   9, 781,  17],\n",
       "       [ 48,  49,   3,  26,   2,   4,   7,  35,  12, 814]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf = confusion_matrix(cf_label, cf_pred)\n",
    "cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[8686,  314],\n",
       "        [ 214,  786]],\n",
       "\n",
       "       [[8931,   69],\n",
       "        [ 180,  820]],\n",
       "\n",
       "       [[8762,  238],\n",
       "        [ 479,  521]],\n",
       "\n",
       "       [[8373,  627],\n",
       "        [ 460,  540]],\n",
       "\n",
       "       [[8669,  331],\n",
       "        [ 256,  744]],\n",
       "\n",
       "       [[8544,  456],\n",
       "        [ 325,  675]],\n",
       "\n",
       "       [[8822,  178],\n",
       "        [ 225,  775]],\n",
       "\n",
       "       [[8716,  284],\n",
       "        [ 179,  821]],\n",
       "\n",
       "       [[8910,   90],\n",
       "        [ 219,  781]],\n",
       "\n",
       "       [[8864,  136],\n",
       "        [ 186,  814]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf = multilabel_confusion_matrix(cf_label, cf_pred)\n",
    "cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       plane       0.71      0.79      0.75      1000\n",
      "         car       0.92      0.82      0.87      1000\n",
      "        bird       0.69      0.52      0.59      1000\n",
      "         cat       0.46      0.54      0.50      1000\n",
      "        deer       0.69      0.74      0.72      1000\n",
      "         dog       0.60      0.68      0.63      1000\n",
      "        frog       0.81      0.78      0.79      1000\n",
      "       horse       0.74      0.82      0.78      1000\n",
      "        ship       0.90      0.78      0.83      1000\n",
      "       truck       0.86      0.81      0.83      1000\n",
      "\n",
      "    accuracy                           0.73     10000\n",
      "   macro avg       0.74      0.73      0.73     10000\n",
      "weighted avg       0.74      0.73      0.73     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classes = ['plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "cf_label_name = list(map(lambda x: classes[x], cf_label))\n",
    "cf_pred_name =  list(map(lambda x: classes[x], cf_pred))\n",
    "report = classification_report(cf_label_name, cf_pred_name, labels=classes)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
