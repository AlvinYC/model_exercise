{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://pytorch.org/\n",
    "from os import path\n",
    "#from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "#platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "#accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
    "#!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "#from scikit-learn import multilabel_confusion_matrix\n",
    "from sklearn.metrics import multilabel_confusion_matrix, confusion_matrix, classification_report\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnn_models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu\n"
     ]
    }
   ],
   "source": [
    "#torch.cuda.device_count()\n",
    "device = \"gpu\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace)\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace)\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace)\n",
      "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU(inplace)\n",
      "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU(inplace)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace)\n",
      "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (36): ReLU(inplace)\n",
      "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (39): ReLU(inplace)\n",
      "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU(inplace)\n",
      "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (44): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      "  (softmax): LogSoftmax()\n",
      ")\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alvin/notebook/pytorch_model_excercise/models.py:135: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = self.softmax(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.118\n",
      "[1,  4000] loss: 1.922\n",
      "[1,  6000] loss: 1.789\n",
      "[2,  2000] loss: 1.678\n",
      "[2,  4000] loss: 1.576\n",
      "[2,  6000] loss: 1.511\n",
      "[3,  2000] loss: 1.404\n",
      "[3,  4000] loss: 1.361\n",
      "[3,  6000] loss: 1.293\n",
      "[4,  2000] loss: 1.210\n",
      "[4,  4000] loss: 1.182\n",
      "[4,  6000] loss: 1.162\n",
      "[5,  2000] loss: 1.063\n",
      "[5,  4000] loss: 1.073\n",
      "[5,  6000] loss: 1.021\n",
      "[6,  2000] loss: 0.948\n",
      "[6,  4000] loss: 0.937\n",
      "[6,  6000] loss: 0.924\n",
      "[7,  2000] loss: 0.839\n",
      "[7,  4000] loss: 0.855\n",
      "[7,  6000] loss: 0.844\n",
      "[8,  2000] loss: 0.762\n",
      "[8,  4000] loss: 0.752\n",
      "[8,  6000] loss: 0.737\n",
      "[9,  2000] loss: 0.665\n",
      "[9,  4000] loss: 0.695\n",
      "[9,  6000] loss: 0.690\n",
      "[10,  2000] loss: 0.589\n",
      "[10,  4000] loss: 0.615\n",
      "[10,  6000] loss: 0.612\n",
      "Finished Training\n",
      "--- 1491.8193638324738 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#net = Net1()\n",
    "net = Net2()\n",
    "#net = Net3()\n",
    "#net = NetCEI201()\n",
    "net = VGG('VGG16')\n",
    "print(net)\n",
    "net.cuda()\n",
    "\n",
    "data_batch_size = 4\n",
    "start_time = time.time()\n",
    "if __name__ == '__main__':\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    trainset  = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "    ## reduce training size -√ç begin\n",
    "    num_train = len(trainset)\n",
    "    indices   = list(range(num_train))\n",
    "    split     = int(np.floor(0.5 * num_train))\n",
    "    np.random.seed(10)\n",
    "    np.random.shuffle(indices)\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    ## reduce training size - end\n",
    "    #trainloader = torch.utils.data.DataLoader(trainset,batch_size=data_batch_size, shuffle=True, num_workers=2)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset,batch_size=data_batch_size, sampler=train_sampler, num_workers=2)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=data_batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    classes = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "    #optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "    train = True\n",
    "    #train = False\n",
    "    if train:\n",
    "        for epoch in range(10):\n",
    "            running_loss = 0.0\n",
    "\n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "                inputs, labels = data\n",
    "                if device == \"gpu\":\n",
    "                    inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())  \n",
    "                else: \n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "                            \n",
    "                optimizer.zero_grad()\n",
    "                output = net(inputs)\n",
    "                loss = criterion(output, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                #running_loss += loss.data[0]\n",
    "                running_loss += loss.data.item()\n",
    "\n",
    "                if i % 2000 == 1999:\n",
    "                    print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 2000))\n",
    "                    running_loss = 0.0\n",
    "\n",
    "        print('Finished Training')\n",
    "\n",
    "        torch.save(net.state_dict(), './00_cifar10-Net-model')\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load('./00_cifar10-Net-model'))\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "for i, data in enumerate(testloader, 0):\n",
    "    inputs, labels = data\n",
    "    inputs, targets = data\n",
    "    \n",
    "    images = Variable(inputs.cuda()) if device == \"gpu\" else Variable(inputs)\n",
    "    labels = Variable(labels.cuda()) if device == \"gpu\" else Variable(labels)\n",
    "\n",
    "    output = net(images)\n",
    "\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    c = predicted.eq(labels.data).squeeze()\n",
    "    for j in range(4):\n",
    "        label = int(targets[j])\n",
    "        class_correct[label] += int(c[j])\n",
    "        class_total[label] += 1\n",
    "        total += 1\n",
    "        correct += int(c[j])\n",
    "    \n",
    "print('correct = ' + str(correct))\n",
    "print('total = ' + str(total))\n",
    "print('Total test accuracy : %3.2f %%' %(100 * int(correct) / total))\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %3.2f %% on %d, %d' \n",
    "          %(classes[i], 100 * int(class_correct[i]) // int(class_total[i]), class_correct[i],class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct = 7314\n",
      "total = 10000\n",
      "Total test accuracy : 73.14 %\n",
      "Accuracy of plane : 76.00 % on 761, 1000\n",
      "Accuracy of   car : 86.00 % on 865, 1000\n",
      "Accuracy of  bird : 64.00 % on 641, 1000\n",
      "Accuracy of   cat : 60.00 % on 605, 1000\n",
      "Accuracy of  deer : 65.00 % on 653, 1000\n",
      "Accuracy of   dog : 57.00 % on 579, 1000\n",
      "Accuracy of  frog : 74.00 % on 745, 1000\n",
      "Accuracy of horse : 78.00 % on 787, 1000\n",
      "Accuracy of  ship : 82.00 % on 820, 1000\n",
      "Accuracy of truck : 85.00 % on 858, 1000\n",
      "----------------------------\n",
      "confusion matrix\n",
      "[[761   9  61  23  19   1   0   6  58  62]\n",
      " [  9 865   4  17   2   0   6   3  17  77]\n",
      " [ 64   8 641  84  66  60  35  22  12   8]\n",
      " [ 19   3  90 605  42 139  46  29  10  17]\n",
      " [ 20   0  99 104 653  23  26  67   4   4]\n",
      " [  8   0  63 246  31 579  12  48   2  11]\n",
      " [  4   3  57 144  23  11 745   2  10   1]\n",
      " [ 12   3  22  54  65  37   4 787   0  16]\n",
      " [ 66  33  13  20   1   2   7   4 820  34]\n",
      " [ 23  59   3  31   1   0   1  11  13 858]]\n"
     ]
    }
   ],
   "source": [
    "net.load_state_dict(torch.load('./00_cifar10-Net-model'))\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "cf_label = []\n",
    "cf_pred = []\n",
    "\n",
    "\n",
    "for i, data in enumerate(testloader, 0):\n",
    "    inputs, labels = data\n",
    "    inputs, targets = data\n",
    "\n",
    "    images = Variable(inputs.cuda())\n",
    "    labels = Variable(labels.cuda())\n",
    "    #images = Variable(inputs)\n",
    "    #labels = Variable(labels)\n",
    "\n",
    "    output = net(images)\n",
    "\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    c = predicted.eq(labels.data).squeeze()\n",
    "    for j in range(4):\n",
    "        label = int(targets[j])\n",
    "        class_correct[label] += int(c[j])\n",
    "        class_total[label] += 1\n",
    "        total += 1\n",
    "        correct += int(c[j])\n",
    "    \n",
    "    cf_label += labels.tolist()                           # <---- here\n",
    "    cf_pred += predicted.tolist()                         # <---- here\n",
    "print('correct = ' + str(correct))\n",
    "print('total = ' + str(total))\n",
    "print('Total test accuracy : %3.2f %%' %(100 * int(correct) / total))\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %3.2f %% on %d, %d' \n",
    "          %(classes[i], 100 * int(class_correct[i]) // int(class_total[i]), class_correct[i],class_total[i]))\n",
    "    \n",
    "cf = confusion_matrix(cf_label, cf_pred)  # <---- here\n",
    "print('----------------------------\\nconfusion matrix')   # <---- here\n",
    "print(cf)                                                 # <---- here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[761,   9,  61,  23,  19,   1,   0,   6,  58,  62],\n",
       "       [  9, 865,   4,  17,   2,   0,   6,   3,  17,  77],\n",
       "       [ 64,   8, 641,  84,  66,  60,  35,  22,  12,   8],\n",
       "       [ 19,   3,  90, 605,  42, 139,  46,  29,  10,  17],\n",
       "       [ 20,   0,  99, 104, 653,  23,  26,  67,   4,   4],\n",
       "       [  8,   0,  63, 246,  31, 579,  12,  48,   2,  11],\n",
       "       [  4,   3,  57, 144,  23,  11, 745,   2,  10,   1],\n",
       "       [ 12,   3,  22,  54,  65,  37,   4, 787,   0,  16],\n",
       "       [ 66,  33,  13,  20,   1,   2,   7,   4, 820,  34],\n",
       "       [ 23,  59,   3,  31,   1,   0,   1,  11,  13, 858]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf = confusion_matrix(cf_label, cf_pred)\n",
    "cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = multilabel_confusion_matrix(cf_label, cf_pred)\n",
    "cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       plane       0.77      0.76      0.77      1000\n",
      "         car       0.88      0.86      0.87      1000\n",
      "        bird       0.61      0.64      0.62      1000\n",
      "         cat       0.46      0.60      0.52      1000\n",
      "        deer       0.72      0.65      0.69      1000\n",
      "         dog       0.68      0.58      0.63      1000\n",
      "        frog       0.84      0.74      0.79      1000\n",
      "       horse       0.80      0.79      0.80      1000\n",
      "        ship       0.87      0.82      0.84      1000\n",
      "       truck       0.79      0.86      0.82      1000\n",
      "\n",
      "    accuracy                           0.73     10000\n",
      "   macro avg       0.74      0.73      0.73     10000\n",
      "weighted avg       0.74      0.73      0.73     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classes = ['plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "cf_label_name = list(map(lambda x: classes[x], cf_label))\n",
    "cf_pred_name =  list(map(lambda x: classes[x], cf_pred))\n",
    "report = classification_report(cf_label_name, cf_pred_name, labels=classes)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
