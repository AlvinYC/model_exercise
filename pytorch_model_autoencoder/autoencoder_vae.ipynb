{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://graviraja.github.io/vanillavae/#\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9920512it [00:04, 2435996.62it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32768it [00:00, 54982.11it/s]                           \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1654784it [00:02, 820269.63it/s]                             \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8192it [00:00, 21016.67it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "transforms = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = datasets.MNIST('./data',train=True,download=True,transform=transforms)\n",
    "test_dataset = datasets.MNIST('./data',train=False,download=True,transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64     # number of data points in each batch\n",
    "N_EPOCHS = 50       # times to run the model on complete data\n",
    "INPUT_DIM = 28 * 28 # size of each input\n",
    "HIDDEN_DIM = 256    # hidden dimension\n",
    "LATENT_DIM = 20     # latent vector dimension\n",
    "lr = 1e-3           # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_iterator = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    ''' This the encoder part of VAE\n",
    "\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim, z_dim):\n",
    "        '''\n",
    "        Args:\n",
    "            input_dim: A integer indicating the size of input (in case of MNIST 28 * 28).\n",
    "            hidden_dim: A integer indicating the size of hidden dimension.\n",
    "            z_dim: A integer indicating the latent dimension.\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear = nn.Linear(input_dim, hidden_dim)\n",
    "        self.mu = nn.Linear(hidden_dim, z_dim)\n",
    "        self.var = nn.Linear(hidden_dim, z_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is of shape [batch_size, input_dim]\n",
    "\n",
    "        hidden = F.relu(self.linear(x))\n",
    "        # hidden is of shape [batch_size, hidden_dim]\n",
    "        z_mu = self.mu(hidden)\n",
    "        # z_mu is of shape [batch_size, latent_dim]\n",
    "        z_var = self.var(hidden)\n",
    "        # z_var is of shape [batch_size, latent_dim]\n",
    "\n",
    "        return z_mu, z_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    ''' This the decoder part of VAE\n",
    "\n",
    "    '''\n",
    "    def __init__(self, z_dim, hidden_dim, output_dim):\n",
    "        '''\n",
    "        Args:\n",
    "            z_dim: A integer indicating the latent size.\n",
    "            hidden_dim: A integer indicating the size of hidden dimension.\n",
    "            output_dim: A integer indicating the output dimension (in case of MNIST it is 28 * 28)\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear = nn.Linear(z_dim, hidden_dim)\n",
    "        self.out = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is of shape [batch_size, latent_dim]\n",
    "\n",
    "        hidden = F.relu(self.linear(x))\n",
    "        # hidden is of shape [batch_size, hidden_dim]\n",
    "\n",
    "        predicted = torch.sigmoid(self.out(hidden))\n",
    "        # predicted is of shape [batch_size, output_dim]\n",
    "\n",
    "        return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    ''' This the VAE, which takes a encoder and decoder.\n",
    "\n",
    "    '''\n",
    "    def __init__(self, enc, dec):\n",
    "        super().__init__()\n",
    "\n",
    "        self.enc = enc\n",
    "        self.dec = dec\n",
    "\n",
    "    def forward(self, x):\n",
    "        # encode\n",
    "        z_mu, z_var = self.enc(x)\n",
    "\n",
    "        # sample from the distribution having latent parameters z_mu, z_var\n",
    "        # reparameterize\n",
    "        std = torch.exp(z_var / 2)\n",
    "        eps = torch.randn_like(std)\n",
    "        x_sample = eps.mul(std).add_(z_mu)\n",
    "\n",
    "        # decode\n",
    "        predicted = self.dec(x_sample)\n",
    "        return predicted, z_mu, z_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder\n",
    "encoder = Encoder(INPUT_DIM, HIDDEN_DIM, LATENT_DIM)\n",
    "\n",
    "# decoder\n",
    "decoder = Decoder(LATENT_DIM, HIDDEN_DIM, INPUT_DIM)\n",
    "\n",
    "# vae\n",
    "model = VAE(encoder, decoder).to(device)\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # set the train mode\n",
    "    model.train()\n",
    "\n",
    "    # loss of the epoch\n",
    "    train_loss = 0\n",
    "\n",
    "    for i, (x, _) in enumerate(train_iterator):\n",
    "        # reshape the data into [batch_size, 784]\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = x.to(device)\n",
    "\n",
    "        # update the gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        x_sample, z_mu, z_var = model(x)\n",
    "\n",
    "        # reconstruction loss\n",
    "        recon_loss = F.binary_cross_entropy(x_sample, x, size_average=False)\n",
    "\n",
    "        # kl divergence loss\n",
    "        kl_loss = 0.5 * torch.sum(torch.exp(z_var) + z_mu**2 - 1.0 - z_var)\n",
    "\n",
    "        # total loss\n",
    "        loss = recon_loss + kl_loss\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    # set the evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # test loss for the data\n",
    "    test_loss = 0\n",
    "\n",
    "    # we don't need to track the gradients, since we are not updating the parameters during evaluation / testing\n",
    "    with torch.no_grad():\n",
    "        for i, (x, _) in enumerate(test_iterator):\n",
    "            # reshape the data\n",
    "            x = x.view(-1, 28 * 28)\n",
    "            x = x.to(device)\n",
    "\n",
    "            # forward pass\n",
    "            x_sample, z_mu, z_var = model(x)\n",
    "\n",
    "            # reconstruction loss\n",
    "            recon_loss = F.binary_cross_entropy(x_sample, x, size_average=False)\n",
    "\n",
    "            # kl divergence loss\n",
    "            kl_loss = 0.5 * torch.sum(torch.exp(z_var) + z_mu**2 - 1.0 - z_var)\n",
    "\n",
    "            # total loss\n",
    "            loss = recon_loss + kl_loss\n",
    "            test_loss += loss.item()\n",
    "\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train Loss: 106.50, Test Loss: 105.89\n",
      "Epoch 1, Train Loss: 106.26, Test Loss: 105.99\n",
      "Epoch 2, Train Loss: 105.98, Test Loss: 105.22\n",
      "Epoch 3, Train Loss: 105.81, Test Loss: 105.32\n",
      "Epoch 4, Train Loss: 105.63, Test Loss: 105.30\n",
      "Epoch 5, Train Loss: 105.42, Test Loss: 104.98\n",
      "Epoch 6, Train Loss: 105.28, Test Loss: 105.02\n",
      "Epoch 7, Train Loss: 105.11, Test Loss: 104.83\n",
      "Epoch 8, Train Loss: 104.96, Test Loss: 104.73\n",
      "Epoch 9, Train Loss: 104.86, Test Loss: 104.80\n",
      "Epoch 10, Train Loss: 104.72, Test Loss: 104.64\n",
      "Epoch 11, Train Loss: 104.57, Test Loss: 104.36\n",
      "Epoch 12, Train Loss: 104.50, Test Loss: 104.21\n",
      "Epoch 13, Train Loss: 104.44, Test Loss: 104.23\n",
      "Epoch 14, Train Loss: 104.31, Test Loss: 104.19\n",
      "Epoch 15, Train Loss: 104.23, Test Loss: 104.01\n",
      "Epoch 16, Train Loss: 104.13, Test Loss: 104.00\n",
      "Epoch 17, Train Loss: 104.08, Test Loss: 103.85\n",
      "Epoch 18, Train Loss: 103.99, Test Loss: 103.63\n",
      "Epoch 19, Train Loss: 103.90, Test Loss: 103.66\n",
      "Epoch 20, Train Loss: 103.84, Test Loss: 103.71\n",
      "Epoch 21, Train Loss: 103.75, Test Loss: 103.62\n",
      "Epoch 22, Train Loss: 103.71, Test Loss: 103.64\n",
      "Epoch 23, Train Loss: 103.62, Test Loss: 103.64\n",
      "Epoch 24, Train Loss: 103.61, Test Loss: 103.39\n",
      "Epoch 25, Train Loss: 103.52, Test Loss: 103.40\n",
      "Epoch 26, Train Loss: 103.47, Test Loss: 103.37\n",
      "Epoch 27, Train Loss: 103.44, Test Loss: 103.24\n",
      "Epoch 28, Train Loss: 103.40, Test Loss: 103.28\n",
      "Epoch 29, Train Loss: 103.34, Test Loss: 103.28\n",
      "Epoch 30, Train Loss: 103.32, Test Loss: 103.27\n"
     ]
    }
   ],
   "source": [
    "best_test_loss = float('inf')\n",
    "\n",
    "for e in range(N_EPOCHS):\n",
    "\n",
    "    train_loss = train()\n",
    "    test_loss = test()\n",
    "\n",
    "    train_loss /= len(train_dataset)\n",
    "    test_loss /= len(test_dataset)\n",
    "\n",
    "    print(f'Epoch {e}, Train Loss: {train_loss:.2f}, Test Loss: {test_loss:.2f}')\n",
    "\n",
    "    if best_test_loss > test_loss:\n",
    "        best_test_loss = test_loss\n",
    "        patience_counter = 1\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter > 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20])\n",
      "torch.Size([28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f388049ee48>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f38804f4358>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sample and generate a image\n",
    "z = torch.randn(1, LATENT_DIM).to(device)\n",
    "\n",
    "# run only the decoder\n",
    "reconstructed_img = model.dec(z)\n",
    "img = reconstructed_img.view(28, 28).data.cpu()\n",
    "\n",
    "print(z.shape)\n",
    "print(img.shape)\n",
    "\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
